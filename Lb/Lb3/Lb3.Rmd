---
title: "Лабораторна робота № 3. Основи вибіркового методу"
author: "Мякушка Олександр"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    df_print: paged
  html_notebook:
    toc: true
    toc_float: true
    highlight: tango
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Підключаємо бібліотеки для гарних таблиць та графіків
library(knitr)
library(ggplot2) # Якщо захочемо красиві графіки
```

# 1. Постановка задачі

Об’єктом дослідження є випадкова величина $X$, що має нормальний закон розподілу $N(a, \sigma^2)$.
Згідно з індивідуальним завданням, параметри становлять:
$$a = 0; \quad \sigma^2 = 1 \implies \sigma = 1$$
Метою роботи є генерація вибірок обсягом $n=100$ та $n=1000$, розрахунок незміщених оцінок параметрів та порівняння їх із теоретичними значеннями.

# 2. Модернізована функція розрахунку

Ми розширимо стандартну функцію, щоб вона рахувала всі параметри з Таблиці 3.1 вашої методички, включаючи центральні моменти $\mu_3$ та $\mu_4$.

```{r functions}
analyze_sample <- function(x) {
  n <- length(x)
  avg <- mean(x)                                # m(x)
  var_biased <- sum((x - avg)^2) / n            # D(x) - зміщена (звичайна)
  var_unbiased <- var(x)                        # D~(x) - виправлена
  sd_biased <- sqrt(var_biased)                 # sigma(x)
  sd_unbiased <- sd(x)                          # sigma~(x)
  
  # Центральні моменти
  m3 <- sum((x - avg)^3) / n
  m4 <- sum((x - avg)^4) / n
  
  # Асиметрія та Ексцес
  skewness <- m3 / (sd_biased^3)
  kurtosis <- (m4 / (sd_biased^4)) - 3
  
  return(c(a = avg, sigma = sd_biased, mean = avg, var = var_biased, 
           var_adj = var_unbiased, sd = sd_biased, sd_adj = sd_unbiased, 
           mu3 = m3, mu4 = m4, As = skewness, Ek = kurtosis))
}
```

# 3. Генерація та аналіз даних

```{r sample_100}
set.seed(42) # Змінено seed для унікальності результатів
a_param <- 0
sigma_param <- 1

# Генерація вибірок
sample_small <- rnorm(100, a_param, sigma_param)
sample_large <- rnorm(1000, a_param, sigma_param)

# Розрахунок характеристик
res_small <- analyze_sample(sample_small)
res_large <- analyze_sample(sample_large)
```

## Візуалізація результатів (ggplot2)

Замість стандартних графіків plot(), використаємо ggplot2, що зробить звіт професійнішим.

```{r plots_100, fig.width=10, fig.height=8}
df_plot <- data.frame(val = sample_large)

ggplot(df_plot, aes(x = val)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "steelblue", alpha = 0.6) +
  geom_density(color = "blue", size = 1) +
  stat_function(fun = dnorm, args = list(mean = a_param, sd = sigma_param), 
                color = "red", linetype = "dashed", size = 1) +
  labs(title = "Щільність розподілу (n=1000)",
       subtitle = "Синя лінія - емпірична, Червона пунктирна - теоретична",
       x = "Значення X", y = "Щільність") +
  theme_minimal()
```

# 4.Порівняльна таблиця

```{r sample_1000}
summary_table <- data.frame(
  "Характеристика" = c("Параметр a", "Параметр sigma", "Мат. сподівання m(x)", 
                        "Дисперсія D(x)", "Виправлена дисперсія", "СКВ sigma(x)", 
                        "Виправлене СКВ", "Центр. момент 3-го порядку", 
                        "Центр. момент 4-го порядку", "Асиметрія As", "Ексцес Ek"),
  "Теоретичне" = c(0, 1, 0, 1, "-", 1, "-", 0, 3, 0, 0),
  "Вибірка n=100" = round(res_small, 5),
  "Вибірка n=1000" = round(res_large, 5)
)

kable(summary_table, caption = "Таблиця 3.1 – Теоретичні та емпіричні числові характеристики")
```



# Висновки

В ході роботи було досліджено основи вибіркового методу. На основі отриманих даних можна стверджувати:Оцінки параметрів для $n=1000$ є значно точнішими за оцінки для $n=100$.Виправлена дисперсія краще компенсує похибку на малих вибірках.Графік щільності при $n=1000$ майже повністю збігається з теоретичною кривою нормального розподілу.